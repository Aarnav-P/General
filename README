This file contains a description of each file in this repo, and the skills learned from. Only files that can demonstrate useful/worthwhile progress are included.
OLDEST TO NEWEST:

'Chi2_fit_to_data.py' - Python script that computes the Chi-squared value of a set of bivariate data
      > Skills learned:
        - Intro to arrays, replacement fields, measures of statistical relevance
        
'Curve_fit.py' - Using Least-Squares-Fit-Regression(LSFR) to define a function
      > Skills learned:
        - Defining a function, better proficiency with matplotlib, how to learn a set of functions quickly.

'Boltzmann.py' - Used for a lab experiment to determine the value of Boltzmann's constant and absolute zero. 
      > Skills learned:
        - Synthesising previous skills, introduction to pandas module and the dataframe (df) storage type

'pytorch 1 - tensors.py' - The start of my endeavour to learn and be able to fluidly use Machine Learning techniques. 
   # "Why pytorch and not tensorflow?
   # pytorch is less automated, I am aiming to get a fuller understanding of how using machine learning actually
     works in practice, so that I can independently use it for any project I decide to apply it to."
      > Skills learned
        - Understanding what a tensor object is in pytorch, broadcasting rules for tensors, advantages of tensors over arrays, some basic ML concepts 
        (weighting, averaging over data sets by using  multi-dim tensors)

'vector field visualising.py' - Playing with the matplotlib library to better represent data.
      > Skills learned:
        - Using 'quiver' and 'streamplot' subfunctions, data presentation customisation.
      > To-do: Understand dictionaries and further explore Matplotlib

'pytorch 2 - basic networks.py' - Conceptualising what a loss function represents through visualising partial derivatives in lower-dimensional space 
                                  and extrapolating the concept. Understanding how a NN (Neural Network) fundamentally works.
      > Skills learned:
        - Creating basic NN's, Simple loss and optimisation function, Purpose and limitations of NN's
      > To-do:
        - Understanding classes, subclasses etc. and OOP better.  

'classes.py' - Starting back on the ML path. Needed to address the issue of understanding classes that was outlined in 'pytorch 2...'

"PASS" Files - Programs created to help teach some nice tricks and uses of fitting functions and procedures to 1st Year Peer support scheme mentees.
      # At this point, I've realised there are lots of small programs I can upload, but most are not particularly interesting or noteworthy so I will leave them out to avoid clutter.

'pytorch 3 - cross-entropy loss function.py' - Exploring waht the cross-entropy loss function is, how it optimises data and how to implement it.
      > Skills learned:
        - Applying Lagrange Multipliers to constraint optimisation problems
      > To-do:
        - Continue file: Why the exponential normalisation?
        - Image segmentation
        - So far I've only performed optimisation. ML should fit a non-differentiable metric using a proxy such as Cross-entropy loss, and should fit unseen data not just existing data.
            - Previous matrices were effectively only 1 independent parameter, need to introduce some sort of non-linearity AB(A) so that AB is not computatable as one matrix C

'a07380ap_zboson.py' - I try to avoid posting mundane lab scripts now, but this piece of code was a very large step up for me in terms of functional, recursive, and more efficient programming.
                       Additionally, there are much, much better graphical visualisations here, so I think it serves well enough as a progress update. 

'Plotting_mega.py' - A nice general purpose piece of code for data plotting. Handles 2D data with 1 or both uncertainties, linear or non-linear, and provides curve-fitting and chi-squared calculations.
                     Functionalities like peak-finding have been and will be added as required.
                     12/11/24 - Data smoothing functionality for noise added in two modes: rolling average and gaussian convolution
                     Credit to Lukas Wystemp for the outline and idea.
